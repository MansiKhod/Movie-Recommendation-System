{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-17T18:01:15.905803Z","iopub.status.busy":"2024-02-17T18:01:15.905436Z","iopub.status.idle":"2024-02-17T18:01:15.911344Z","shell.execute_reply":"2024-02-17T18:01:15.909432Z","shell.execute_reply.started":"2024-02-17T18:01:15.905775Z"},"trusted":true},"outputs":[],"source":["%pip install pandas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["importing the python libraries "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:15.913765Z","iopub.status.busy":"2024-02-17T18:01:15.913327Z","iopub.status.idle":"2024-02-17T18:01:16.298562Z","shell.execute_reply":"2024-02-17T18:01:16.297714Z","shell.execute_reply.started":"2024-02-17T18:01:15.913738Z"},"trusted":true},"outputs":[],"source":["movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n","credits = pd.read_csv(\"tmdb_5000_credits.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["uploading the datasets, movies and credits"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.299730Z","iopub.status.busy":"2024-02-17T18:01:16.299486Z","iopub.status.idle":"2024-02-17T18:01:16.313797Z","shell.execute_reply":"2024-02-17T18:01:16.312559Z","shell.execute_reply.started":"2024-02-17T18:01:16.299709Z"},"trusted":true},"outputs":[],"source":["movies.head"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.316719Z","iopub.status.busy":"2024-02-17T18:01:16.316389Z","iopub.status.idle":"2024-02-17T18:01:16.327767Z","shell.execute_reply":"2024-02-17T18:01:16.327121Z","shell.execute_reply.started":"2024-02-17T18:01:16.316691Z"},"trusted":true},"outputs":[],"source":["credits.head"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.329102Z","iopub.status.busy":"2024-02-17T18:01:16.328826Z","iopub.status.idle":"2024-02-17T18:01:16.340074Z","shell.execute_reply":"2024-02-17T18:01:16.339213Z","shell.execute_reply.started":"2024-02-17T18:01:16.329081Z"},"trusted":true},"outputs":[],"source":["movies.shape"]},{"cell_type":"markdown","metadata":{},"source":["Shape is nothing but the quantity of rows and columns present in the datasets."]},{"cell_type":"markdown","metadata":{},"source":["We have 4803 movies stored in rows along with 20 columns of different atrributes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.341325Z","iopub.status.busy":"2024-02-17T18:01:16.341092Z","iopub.status.idle":"2024-02-17T18:01:16.348366Z","shell.execute_reply":"2024-02-17T18:01:16.347557Z","shell.execute_reply.started":"2024-02-17T18:01:16.341306Z"},"trusted":true},"outputs":[],"source":["credits.shape"]},{"cell_type":"markdown","metadata":{},"source":["Similar to 'movies' dataset, 'credits' dataset has 4803 movies along with 4 columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.349793Z","iopub.status.busy":"2024-02-17T18:01:16.349573Z","iopub.status.idle":"2024-02-17T18:01:16.367277Z","shell.execute_reply":"2024-02-17T18:01:16.365999Z","shell.execute_reply.started":"2024-02-17T18:01:16.349774Z"},"trusted":true},"outputs":[],"source":["movies = movies.merge(credits,on='title')"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["merging both datasets to work on both of them at once. As there are 4803 movies, that many rows are present. 20 columns are present in movies and 4 in shapes, but the 'title' column is common in both of them so there are in total 23 columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.369129Z","iopub.status.busy":"2024-02-17T18:01:16.368779Z","iopub.status.idle":"2024-02-17T18:01:16.390396Z","shell.execute_reply":"2024-02-17T18:01:16.389061Z","shell.execute_reply.started":"2024-02-17T18:01:16.369103Z"},"trusted":true},"outputs":[],"source":["movies.head"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.394669Z","iopub.status.busy":"2024-02-17T18:01:16.394339Z","iopub.status.idle":"2024-02-17T18:01:16.412498Z","shell.execute_reply":"2024-02-17T18:01:16.411635Z","shell.execute_reply.started":"2024-02-17T18:01:16.394643Z"},"trusted":true},"outputs":[],"source":["movies.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.413955Z","iopub.status.busy":"2024-02-17T18:01:16.413622Z","iopub.status.idle":"2024-02-17T18:01:16.420248Z","shell.execute_reply":"2024-02-17T18:01:16.418717Z","shell.execute_reply.started":"2024-02-17T18:01:16.413917Z"},"trusted":true},"outputs":[],"source":["movies = movies[['id',  'title','genres', 'keywords', 'overview', 'cast', 'crew']]"]},{"cell_type":"markdown","metadata":{},"source":["Eliminating all the unnecessary columns that won't be effective in recommending the movies.\n","['id',  'title','genres', 'keywords', 'overview', 'cast', 'crew'] are all the columns that we'll be considering for the next steps."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.422140Z","iopub.status.busy":"2024-02-17T18:01:16.421794Z","iopub.status.idle":"2024-02-17T18:01:16.443011Z","shell.execute_reply":"2024-02-17T18:01:16.441965Z","shell.execute_reply.started":"2024-02-17T18:01:16.422112Z"},"trusted":true},"outputs":[],"source":["movies.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.444762Z","iopub.status.busy":"2024-02-17T18:01:16.444384Z","iopub.status.idle":"2024-02-17T18:01:16.456505Z","shell.execute_reply":"2024-02-17T18:01:16.455114Z","shell.execute_reply.started":"2024-02-17T18:01:16.444730Z"},"trusted":true},"outputs":[],"source":["movies.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["checking if any of the columns in movies dataset is missing any value. since there are only 3 values that are missing in the dataset, we can easily ignore them."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.458539Z","iopub.status.busy":"2024-02-17T18:01:16.458203Z","iopub.status.idle":"2024-02-17T18:01:16.472284Z","shell.execute_reply":"2024-02-17T18:01:16.470940Z","shell.execute_reply.started":"2024-02-17T18:01:16.458511Z"},"trusted":true},"outputs":[],"source":["movies.dropna(inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["This line of code removes any rows from the DataFrame that has any one missing value. since we are modifying the dataframe from the original itself, once we clean the missing values, we won't get any missing value in the original dataset. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.474732Z","iopub.status.busy":"2024-02-17T18:01:16.474012Z","iopub.status.idle":"2024-02-17T18:01:16.486194Z","shell.execute_reply":"2024-02-17T18:01:16.485259Z","shell.execute_reply.started":"2024-02-17T18:01:16.474706Z"},"trusted":true},"outputs":[],"source":["movies.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.487759Z","iopub.status.busy":"2024-02-17T18:01:16.487488Z","iopub.status.idle":"2024-02-17T18:01:16.575126Z","shell.execute_reply":"2024-02-17T18:01:16.574443Z","shell.execute_reply.started":"2024-02-17T18:01:16.487736Z"},"trusted":true},"outputs":[],"source":["movies.duplicated().sum()"]},{"cell_type":"markdown","metadata":{},"source":["we have checked for any duplicate data in the datset, since there is no duplicate data, it shows 0."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.577313Z","iopub.status.busy":"2024-02-17T18:01:16.576908Z","iopub.status.idle":"2024-02-17T18:01:16.584618Z","shell.execute_reply":"2024-02-17T18:01:16.583362Z","shell.execute_reply.started":"2024-02-17T18:01:16.577282Z"},"trusted":true},"outputs":[],"source":["movies.iloc[0].genres"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import ast"]},{"cell_type":"markdown","metadata":{},"source":["since the genres is in a little confused manner, we want to convert the column values into the list format, such as ['Action', 'Adventure', 'Fantasy', 'Science Fiction']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.586213Z","iopub.status.busy":"2024-02-17T18:01:16.585810Z","iopub.status.idle":"2024-02-17T18:01:16.593835Z","shell.execute_reply":"2024-02-17T18:01:16.592911Z","shell.execute_reply.started":"2024-02-17T18:01:16.586189Z"},"trusted":true},"outputs":[],"source":["def convert(obj):\n","    L=[]\n","    for i in ast.literal_eval(obj):\n","        L.append(i['name'])\n","    return L"]},{"cell_type":"markdown","metadata":{},"source":["calling the convert function as it is will not work properly as genres is a string of dictionaries with keys and values. First, we have to convert the string into a list aand each dictionary into a python object."]},{"cell_type":"markdown","metadata":{},"source":["For the same purpose, there is a function in Python known as \"ast.literal_eval()\"\n","\n","\"ast.literal_eval()\" is a Python function that safely evaluates strings containing Python expressions or literals. It takes a string representing a Python literal, such as a dictionary, list, tuple, etc., and converts it into the corresponding Python object."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.595505Z","iopub.status.busy":"2024-02-17T18:01:16.595168Z","iopub.status.idle":"2024-02-17T18:01:16.607384Z","shell.execute_reply":"2024-02-17T18:01:16.606317Z","shell.execute_reply.started":"2024-02-17T18:01:16.595475Z"},"trusted":true},"outputs":[],"source":["import ast\n","ast.literal_eval('[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.609226Z","iopub.status.busy":"2024-02-17T18:01:16.608773Z","iopub.status.idle":"2024-02-17T18:01:16.776292Z","shell.execute_reply":"2024-02-17T18:01:16.775296Z","shell.execute_reply.started":"2024-02-17T18:01:16.609197Z"},"trusted":true},"outputs":[],"source":["movies['genres'] = movies['genres'].apply(convert)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.777611Z","iopub.status.busy":"2024-02-17T18:01:16.777397Z","iopub.status.idle":"2024-02-17T18:01:16.791090Z","shell.execute_reply":"2024-02-17T18:01:16.790045Z","shell.execute_reply.started":"2024-02-17T18:01:16.777593Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"markdown","metadata":{},"source":["Now, as we can see Genres have been all simplified into lists. We'll do the same for keywords."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:16.792648Z","iopub.status.busy":"2024-02-17T18:01:16.792308Z","iopub.status.idle":"2024-02-17T18:01:17.207513Z","shell.execute_reply":"2024-02-17T18:01:17.206425Z","shell.execute_reply.started":"2024-02-17T18:01:16.792619Z"},"trusted":true},"outputs":[],"source":["movies['keywords'] = movies['keywords'].apply(convert)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:17.210241Z","iopub.status.busy":"2024-02-17T18:01:17.209990Z","iopub.status.idle":"2024-02-17T18:01:17.226582Z","shell.execute_reply":"2024-02-17T18:01:17.225284Z","shell.execute_reply.started":"2024-02-17T18:01:17.210220Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:17.228710Z","iopub.status.busy":"2024-02-17T18:01:17.228313Z","iopub.status.idle":"2024-02-17T18:01:17.235544Z","shell.execute_reply":"2024-02-17T18:01:17.234382Z","shell.execute_reply.started":"2024-02-17T18:01:17.228681Z"},"trusted":true},"outputs":[],"source":["movies['cast'][0]"]},{"cell_type":"markdown","metadata":{},"source":["There is no need for all the otherr information. In this string also, only 'name' key is important. ALso, we'll be fetching only 3 actor's/actress's names from the above data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:17.242394Z","iopub.status.busy":"2024-02-17T18:01:17.242072Z","iopub.status.idle":"2024-02-17T18:01:17.247830Z","shell.execute_reply":"2024-02-17T18:01:17.246627Z","shell.execute_reply.started":"2024-02-17T18:01:17.242367Z"},"trusted":true},"outputs":[],"source":["def convert3(obj):\n","    L=[]\n","    counter = 0 \n","    for i in ast.literal_eval(obj):\n","        if counter != 3:\n","                L.append(i['name'])\n","                counter +=1\n","        else:\n","            break\n","    return L"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:17.249348Z","iopub.status.busy":"2024-02-17T18:01:17.249040Z","iopub.status.idle":"2024-02-17T18:01:20.753101Z","shell.execute_reply":"2024-02-17T18:01:20.752508Z","shell.execute_reply.started":"2024-02-17T18:01:17.249322Z"},"trusted":true},"outputs":[],"source":["movies['cast'] = movies['cast'].apply(convert3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:20.754409Z","iopub.status.busy":"2024-02-17T18:01:20.754054Z","iopub.status.idle":"2024-02-17T18:01:20.760527Z","shell.execute_reply":"2024-02-17T18:01:20.759473Z","shell.execute_reply.started":"2024-02-17T18:01:20.754388Z"},"trusted":true},"outputs":[],"source":["movies['cast'][1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:20.762375Z","iopub.status.busy":"2024-02-17T18:01:20.762111Z","iopub.status.idle":"2024-02-17T18:01:20.780415Z","shell.execute_reply":"2024-02-17T18:01:20.779521Z","shell.execute_reply.started":"2024-02-17T18:01:20.762349Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:20.782361Z","iopub.status.busy":"2024-02-17T18:01:20.781853Z","iopub.status.idle":"2024-02-17T18:01:20.791916Z","shell.execute_reply":"2024-02-17T18:01:20.791096Z","shell.execute_reply.started":"2024-02-17T18:01:20.782335Z"},"trusted":true},"outputs":[],"source":["movies['crew'][1]"]},{"cell_type":"markdown","metadata":{},"source":["From the 'crew' column, only the director's name will get fetched."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:20.793390Z","iopub.status.busy":"2024-02-17T18:01:20.793078Z","iopub.status.idle":"2024-02-17T18:01:20.800310Z","shell.execute_reply":"2024-02-17T18:01:20.799449Z","shell.execute_reply.started":"2024-02-17T18:01:20.793364Z"},"trusted":true},"outputs":[],"source":["import ast\n","def direct(obj):\n","    L=[]\n","    for i in ast.literal_eval(obj):\n","        if i['job']=='Director':\n","            L.append(i['name'])\n","            break\n","    return L"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:20.804898Z","iopub.status.busy":"2024-02-17T18:01:20.804556Z","iopub.status.idle":"2024-02-17T18:01:24.550542Z","shell.execute_reply":"2024-02-17T18:01:24.549032Z","shell.execute_reply.started":"2024-02-17T18:01:20.804873Z"},"trusted":true},"outputs":[],"source":["movies['crew']=movies['crew'].apply(direct)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.551892Z","iopub.status.busy":"2024-02-17T18:01:24.551591Z","iopub.status.idle":"2024-02-17T18:01:24.560477Z","shell.execute_reply":"2024-02-17T18:01:24.559742Z","shell.execute_reply.started":"2024-02-17T18:01:24.551864Z"},"trusted":true},"outputs":[],"source":["movies['crew']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.561765Z","iopub.status.busy":"2024-02-17T18:01:24.561508Z","iopub.status.idle":"2024-02-17T18:01:24.579656Z","shell.execute_reply":"2024-02-17T18:01:24.579017Z","shell.execute_reply.started":"2024-02-17T18:01:24.561744Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"markdown","metadata":{},"source":["Now that the other columns are sorted, we will split the overview column into a list of words in which, each word will act as a tag for  searching."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.581492Z","iopub.status.busy":"2024-02-17T18:01:24.580440Z","iopub.status.idle":"2024-02-17T18:01:24.591950Z","shell.execute_reply":"2024-02-17T18:01:24.591024Z","shell.execute_reply.started":"2024-02-17T18:01:24.581445Z"},"trusted":true},"outputs":[],"source":["movies['overview'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.593900Z","iopub.status.busy":"2024-02-17T18:01:24.593343Z","iopub.status.idle":"2024-02-17T18:01:24.620289Z","shell.execute_reply":"2024-02-17T18:01:24.618790Z","shell.execute_reply.started":"2024-02-17T18:01:24.593867Z"},"trusted":true},"outputs":[],"source":["movies['overview'] = movies['overview'].apply(lambda x:x.split())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.622316Z","iopub.status.busy":"2024-02-17T18:01:24.621946Z","iopub.status.idle":"2024-02-17T18:01:24.643513Z","shell.execute_reply":"2024-02-17T18:01:24.642553Z","shell.execute_reply.started":"2024-02-17T18:01:24.622289Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"markdown","metadata":{},"source":["we will remove the space in between the two words present in the genres, keywords, cast and crew. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.645266Z","iopub.status.busy":"2024-02-17T18:01:24.644513Z","iopub.status.idle":"2024-02-17T18:01:24.684224Z","shell.execute_reply":"2024-02-17T18:01:24.682904Z","shell.execute_reply.started":"2024-02-17T18:01:24.645239Z"},"trusted":true},"outputs":[],"source":["movies['genres'] = movies['genres'].apply(lambda x:[i.replace(' ','') for i in x])\n","movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(' ','') for i in x])\n","movies['cast'] = movies['cast'].apply(lambda x:[i.replace(' ','') for i in x])\n","movies['crew'] = movies['crew'].apply(lambda x:[i.replace(' ','') for i in x])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.686116Z","iopub.status.busy":"2024-02-17T18:01:24.685719Z","iopub.status.idle":"2024-02-17T18:01:24.708614Z","shell.execute_reply":"2024-02-17T18:01:24.707892Z","shell.execute_reply.started":"2024-02-17T18:01:24.686067Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"markdown","metadata":{},"source":["As we'll be using ['overview','generes','keywords','cast','crew'] as tags to search for the movies, we'll be merging them together."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.710420Z","iopub.status.busy":"2024-02-17T18:01:24.709808Z","iopub.status.idle":"2024-02-17T18:01:24.925228Z","shell.execute_reply":"2024-02-17T18:01:24.924170Z","shell.execute_reply.started":"2024-02-17T18:01:24.710394Z"},"trusted":true},"outputs":[],"source":["movies['tags']= movies['overview']+ movies['genres']+ movies['keywords']+ movies['cast']+ movies['crew']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.927279Z","iopub.status.busy":"2024-02-17T18:01:24.926888Z","iopub.status.idle":"2024-02-17T18:01:24.952459Z","shell.execute_reply":"2024-02-17T18:01:24.951208Z","shell.execute_reply.started":"2024-02-17T18:01:24.927250Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"markdown","metadata":{},"source":["now that all the columns that will work as tags are appended together, we'll remove other unnecessary columns. Will create new data frame and will introduce all the columns that are necessary "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.953825Z","iopub.status.busy":"2024-02-17T18:01:24.953546Z","iopub.status.idle":"2024-02-17T18:01:24.959416Z","shell.execute_reply":"2024-02-17T18:01:24.958560Z","shell.execute_reply.started":"2024-02-17T18:01:24.953801Z"},"trusted":true},"outputs":[],"source":["new_df = movies [['id', 'title','tags']]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.960718Z","iopub.status.busy":"2024-02-17T18:01:24.960474Z","iopub.status.idle":"2024-02-17T18:01:24.981004Z","shell.execute_reply":"2024-02-17T18:01:24.980031Z","shell.execute_reply.started":"2024-02-17T18:01:24.960697Z"},"trusted":true},"outputs":[],"source":["new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:24.982597Z","iopub.status.busy":"2024-02-17T18:01:24.982351Z","iopub.status.idle":"2024-02-17T18:01:24.999672Z","shell.execute_reply":"2024-02-17T18:01:24.998601Z","shell.execute_reply.started":"2024-02-17T18:01:24.982576Z"},"trusted":true},"outputs":[],"source":["new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))"]},{"cell_type":"markdown","metadata":{},"source":["we have created a string of tags in which we have attached all the elements that we have previously separated for the sake of simplicity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.001063Z","iopub.status.busy":"2024-02-17T18:01:25.000754Z","iopub.status.idle":"2024-02-17T18:01:25.010425Z","shell.execute_reply":"2024-02-17T18:01:25.009288Z","shell.execute_reply.started":"2024-02-17T18:01:25.001039Z"},"trusted":true},"outputs":[],"source":["new_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.011693Z","iopub.status.busy":"2024-02-17T18:01:25.011470Z","iopub.status.idle":"2024-02-17T18:01:25.020283Z","shell.execute_reply":"2024-02-17T18:01:25.019289Z","shell.execute_reply.started":"2024-02-17T18:01:25.011673Z"},"trusted":true},"outputs":[],"source":["new_df['tags'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.021863Z","iopub.status.busy":"2024-02-17T18:01:25.021430Z","iopub.status.idle":"2024-02-17T18:01:25.034292Z","shell.execute_reply":"2024-02-17T18:01:25.033083Z","shell.execute_reply.started":"2024-02-17T18:01:25.021842Z"},"trusted":true},"outputs":[],"source":["new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())"]},{"cell_type":"markdown","metadata":{},"source":["by recommendation, it is easier to work when all the charecters are in lowercase"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.036297Z","iopub.status.busy":"2024-02-17T18:01:25.035815Z","iopub.status.idle":"2024-02-17T18:01:25.051424Z","shell.execute_reply":"2024-02-17T18:01:25.050180Z","shell.execute_reply.started":"2024-02-17T18:01:25.036261Z"},"trusted":true},"outputs":[],"source":["new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.055128Z","iopub.status.busy":"2024-02-17T18:01:25.052703Z","iopub.status.idle":"2024-02-17T18:01:25.063448Z","shell.execute_reply":"2024-02-17T18:01:25.062156Z","shell.execute_reply.started":"2024-02-17T18:01:25.055081Z"},"trusted":true},"outputs":[],"source":["new_df['tags'][0]"]},{"cell_type":"markdown","metadata":{},"source":["In the above tags column, we have so many unnecessary words like 'in','a','the' and so on. These words are known as stop words that doesn't have any specific meaning, but they are used to present the relationship between the other words."]},{"cell_type":"markdown","metadata":{},"source":["To simplify the data, Bag of Words algorithm is used along with the concept of vectorization.\n","Vectorization will help us recognising how unique the word is in the certain movie tag and in the whole dataset, which will help us searching for the similar movies.\n"]},{"cell_type":"markdown","metadata":{},"source":["How exactly we are going to search for the top 5 similar movies? The answer is, we will first turn each movie's text information into numerical vector. Then, we'll be finding the coordinates of the movie on the graph and then find the distance between a movie and every other movie present in the dataset. From there, we'll be searching for top 5 movies that have shortest distance with the movie, and those 5 movies will be top 5 similar movies."]},{"cell_type":"markdown","metadata":{},"source":["For doing so, we have a separate library in python which will minimize the work, know as ScikitLearn."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.066342Z","iopub.status.busy":"2024-02-17T18:01:25.064877Z","iopub.status.idle":"2024-02-17T18:01:25.071697Z","shell.execute_reply":"2024-02-17T18:01:25.070832Z","shell.execute_reply.started":"2024-02-17T18:01:25.066284Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from collections import Counter\n","\n","cv = CountVectorizer(max_features=5000, stop_words='english')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.074067Z","iopub.status.busy":"2024-02-17T18:01:25.072870Z","iopub.status.idle":"2024-02-17T18:01:25.416059Z","shell.execute_reply":"2024-02-17T18:01:25.415149Z","shell.execute_reply.started":"2024-02-17T18:01:25.074033Z"},"trusted":true},"outputs":[],"source":["vectors = cv.fit_transform(new_df['tags']).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.417654Z","iopub.status.busy":"2024-02-17T18:01:25.417397Z","iopub.status.idle":"2024-02-17T18:01:25.424201Z","shell.execute_reply":"2024-02-17T18:01:25.423222Z","shell.execute_reply.started":"2024-02-17T18:01:25.417633Z"},"trusted":true},"outputs":[],"source":["vectors"]},{"cell_type":"markdown","metadata":{},"source":["This vector variable has taken the count of the meaningful words from each movie's tag column."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:25.425741Z","iopub.status.busy":"2024-02-17T18:01:25.425505Z","iopub.status.idle":"2024-02-17T18:01:25.477652Z","shell.execute_reply":"2024-02-17T18:01:25.476263Z","shell.execute_reply.started":"2024-02-17T18:01:25.425721Z"},"trusted":true},"outputs":[],"source":["cv.get_feature_names()"]},{"cell_type":"markdown","metadata":{},"source":["Now, words like 'action' and 'actions' are similar, but since they have different charecters in it, they will work as different coordinates. \n","Here, we'll be applying stemming. By this concept, the words like ['dance','dancing','dancer'] these will get converted into ['dance','dance','dance']\n","Meaning, all of the words will get converted into there original and most basic forms."]},{"cell_type":"markdown","metadata":{},"source":["nltk is a 'natural language toolkit' that will help us do the same thing."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.478694Z","iopub.status.idle":"2024-02-17T18:01:25.479182Z","shell.execute_reply":"2024-02-17T18:01:25.478955Z","shell.execute_reply.started":"2024-02-17T18:01:25.478937Z"},"trusted":true},"outputs":[],"source":["%pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.480950Z","iopub.status.idle":"2024-02-17T18:01:25.481322Z","shell.execute_reply":"2024-02-17T18:01:25.481173Z","shell.execute_reply.started":"2024-02-17T18:01:25.481157Z"},"trusted":true},"outputs":[],"source":["import nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.482248Z","iopub.status.idle":"2024-02-17T18:01:25.482618Z","shell.execute_reply":"2024-02-17T18:01:25.482441Z","shell.execute_reply.started":"2024-02-17T18:01:25.482425Z"},"trusted":true},"outputs":[],"source":["from nltk.stem.porter import PorterStemmer\n","ps = PorterStemmer()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.484190Z","iopub.status.idle":"2024-02-17T18:01:25.484643Z","shell.execute_reply":"2024-02-17T18:01:25.484456Z","shell.execute_reply.started":"2024-02-17T18:01:25.484438Z"},"trusted":true},"outputs":[],"source":["def stem(text):\n","    y=[]\n","    \n","    for i in text.split():\n","        y.append(ps.stem(i))\n","    \n","    return \" \".join(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.487086Z","iopub.status.idle":"2024-02-17T18:01:25.487399Z","shell.execute_reply":"2024-02-17T18:01:25.487267Z","shell.execute_reply.started":"2024-02-17T18:01:25.487254Z"},"trusted":true},"outputs":[],"source":["new_df['tags'] = new_df['tags'].apply(stem)"]},{"cell_type":"markdown","metadata":{},"source":["by stemming, we will get words to their most basic form along also the problem of repeating words won't be occuring."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.488755Z","iopub.status.idle":"2024-02-17T18:01:25.489063Z","shell.execute_reply":"2024-02-17T18:01:25.488913Z","shell.execute_reply.started":"2024-02-17T18:01:25.488901Z"},"trusted":true},"outputs":[],"source":["new_df['tags'].shape"]},{"cell_type":"markdown","metadata":{},"source":["now, we have to calculate distance between the vectors of two movies. That is, we will caalculate the similarity between them using numerical vectors.\n","Here, we have two options based on which we can calculate the distance,\n","1)euclidean distance\n","2)angular or cosine distance\n","\n","Euclidean distance is nothing but the tip-to-tip distance between the two vectors. Euclidean distance will fail the accuracy as higher dimension data will get used.\n","That's why we will be using the cosine distance to measure the distance between them. "]},{"cell_type":"markdown","metadata":{},"source":["Again for this also, we have a 'cosine similarity' function in sklearn."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.489964Z","iopub.status.idle":"2024-02-17T18:01:25.490265Z","shell.execute_reply":"2024-02-17T18:01:25.490147Z","shell.execute_reply.started":"2024-02-17T18:01:25.490135Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.491388Z","iopub.status.idle":"2024-02-17T18:01:25.491652Z","shell.execute_reply":"2024-02-17T18:01:25.491537Z","shell.execute_reply.started":"2024-02-17T18:01:25.491526Z"},"trusted":true},"outputs":[],"source":["similarity = cosine_similarity(vectors)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.492479Z","iopub.status.idle":"2024-02-17T18:01:25.492731Z","shell.execute_reply":"2024-02-17T18:01:25.492617Z","shell.execute_reply.started":"2024-02-17T18:01:25.492607Z"},"trusted":true},"outputs":[],"source":["similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.493612Z","iopub.status.idle":"2024-02-17T18:01:25.493867Z","shell.execute_reply":"2024-02-17T18:01:25.493754Z","shell.execute_reply.started":"2024-02-17T18:01:25.493742Z"},"trusted":true},"outputs":[],"source":["similarity.shape"]},{"cell_type":"markdown","metadata":{},"source":["we got (4806,4806) as the shape of the similarity as we have calculated the distances between 4806 movies withe 4806 movies"]},{"cell_type":"markdown","metadata":{},"source":["From this we can say that, more the value of the similarity, less will be the distance between those two movies and vice versa."]},{"cell_type":"markdown","metadata":{},"source":["Now, we have to create a function that will find the top 5 movies having least distance from the movie we have searched for.\n","-First, when we input the movie name, we'll be searching for the index of that movie\n","-Then, we'll be finding the value of the distance between that movie and all the other movies. But here, we have an issue. When we search for the least distance between the movie we entered and other movies, we have to sort them in reverse order, giving us similarity values from higher order to lower order. But when we'll sort the movies, we'll lost the index count of them, which will again cause the confusion.So, we'll be using 'enumerate' function. By this function, it will change the list of similarities into a tuple having the index number with the similarity distance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.494772Z","iopub.status.idle":"2024-02-17T18:01:25.495072Z","shell.execute_reply":"2024-02-17T18:01:25.494923Z","shell.execute_reply.started":"2024-02-17T18:01:25.494911Z"},"trusted":true},"outputs":[],"source":["sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.496106Z","iopub.status.idle":"2024-02-17T18:01:25.496367Z","shell.execute_reply":"2024-02-17T18:01:25.496250Z","shell.execute_reply.started":"2024-02-17T18:01:25.496238Z"},"trusted":true},"outputs":[],"source":["def recommend(movie):\n","    movie_index = new_df[new_df['title'] == movie].index[0]\n","    distances = similarity[movie_index] \n","    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n","    for i in movies_list:\n","        print(i[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.497342Z","iopub.status.idle":"2024-02-17T18:01:25.497617Z","shell.execute_reply":"2024-02-17T18:01:25.497499Z","shell.execute_reply.started":"2024-02-17T18:01:25.497487Z"},"trusted":true},"outputs":[],"source":["recommend('Avatar')"]},{"cell_type":"markdown","metadata":{},"source":["Now, as we got the indexes of top 5 movies silimar to the movie we have searched for, now we will generate the movie names from these indexes "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.498343Z","iopub.status.idle":"2024-02-17T18:01:25.498612Z","shell.execute_reply":"2024-02-17T18:01:25.498492Z","shell.execute_reply.started":"2024-02-17T18:01:25.498480Z"},"trusted":true},"outputs":[],"source":["print(new_df.iloc[539].title)"]},{"cell_type":"markdown","metadata":{},"source":["using this code, we can easily fetch movie titles from its index. \n","Hence, keeping the whole function as it is, we will be adding the above code, to the function."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:01:25.499701Z","iopub.status.idle":"2024-02-17T18:01:25.500001Z","shell.execute_reply":"2024-02-17T18:01:25.499861Z","shell.execute_reply.started":"2024-02-17T18:01:25.499847Z"},"trusted":true},"outputs":[],"source":["def recommend(movie):\n","    movie_index = new_df[new_df['title'] == movie].index[0]\n","    distances = similarity[movie_index] \n","    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n","    for i in movies_list:\n","        print(new_df.iloc[i[0]].title)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T18:01:35.030265Z","iopub.status.busy":"2024-02-17T18:01:35.029885Z","iopub.status.idle":"2024-02-17T18:01:35.040747Z","shell.execute_reply":"2024-02-17T18:01:35.039822Z","shell.execute_reply.started":"2024-02-17T18:01:35.030236Z"},"trusted":true},"outputs":[],"source":["recommend('Batman Begins')"]},{"cell_type":"markdown","metadata":{},"source":["Now we get the top 5 recommended movies when we search for the name of any movie."]},{"cell_type":"markdown","metadata":{},"source":["As we have develpoed a model and trained it on the dataset, we'll be converting this backend model into a website."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4378898,"sourceId":7517576,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
